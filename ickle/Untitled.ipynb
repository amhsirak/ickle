{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3068598-1c0a-412a-9a90-97f79a63d3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th></th><th>Houston Police Department-HPD</th><th>White     </th><th>Male      </th><th>45279     </th></tr></thead><tbody><tr><td><strong>0</strong></td><td>Houston Fire Department (HFD)</td><td>White     </td><td>Male      </td><td>     63166</td></tr><tr><td><strong>1</strong></td><td>Houston Police Department-HPD</td><td>Black     </td><td>Male      </td><td>     66614</td></tr><tr><td><strong>2</strong></td><td>Public Works & Engineering-PWE</td><td>Asian     </td><td>Male      </td><td>     71680</td></tr><tr><td><strong>3</strong></td><td>Houston Airport System (HAS)</td><td>White     </td><td>Male      </td><td>     42390</td></tr><tr><td><strong>4</strong></td><td>Public Works & Engineering-PWE</td><td>White     </td><td>Male      </td><td>    107962</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<__main__.DataFrame at 0x21bb60a8340>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load C:\\Users\\priya\\OneDrive\\Documents\\ickle\\ickle\\__init__.py\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "\n",
    "class DataFrame:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        A DataFrame holds two dimensional heterogenous data.\n",
    "        Create it by passing a dictionary of NumPy arrays to the values parameter.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        1. data (dict): A dictionary of strings mapped to NumPy arrays. The key will\n",
    "        become the column name.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check for correct input types\n",
    "        self._check_input_types(data)\n",
    "\n",
    "        # Check for equal array lengths\n",
    "        self._check_array_lengths(data)\n",
    "\n",
    "        # Convert unicode arrays to objects\n",
    "        self._data = self._convert_unicode_to_object(data)\n",
    "\n",
    "        # Allow for special methods for strings\n",
    "        self.str = StringMethods(self)\n",
    "        self._add_docs()\n",
    "\n",
    "    def _check_input_types(self,data):\n",
    "        if not isinstance(data, dict):\n",
    "            raise TypeError('`data` can accept only dictionaries')\n",
    "        for key, value in data.items():\n",
    "            if not isinstance(key, str):\n",
    "                raise TypeError('keys of `data` must be of type str')\n",
    "            if not isinstance(value, np.ndarray):\n",
    "                raise TypeError('values of `data` must be NumPy arrays')\n",
    "            if value.ndim != 1:\n",
    "                raise ValueError('values of `data` must be some one-dimensional array')\n",
    "    \n",
    "    # Each column of data in the DataFrame must have the same number of elements.\n",
    "    def _check_array_lengths(self,data):\n",
    "        for i,value in enumerate(data.values()):\n",
    "            if i == 0:\n",
    "                length = len(value)\n",
    "            elif length != len(value):\n",
    "                raise ValueError('All arrays must be of the same length')\n",
    "\n",
    "    def _convert_unicode_to_object(self,data):\n",
    "        # All data from `data` is stored in this `new_data` dictionary\n",
    "        new_data = {}\n",
    "        for key, value in data.items():\n",
    "            if value.dtype.kind == 'U':\n",
    "                new_data[key] = value.astype('object')\n",
    "            else:\n",
    "                new_data[key] = value\n",
    "        return new_data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Make the built-in `len` function work with our dataframe\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int: The number of rows in the dataframe\n",
    "        \"\"\"\n",
    "        # Alternative Way:\n",
    "        # for value in self._data.values():\n",
    "            # value is a NumPy array and they already work with the `len` function\n",
    "            # return len(value)\n",
    "        return len(next(iter(self._data.values())))\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        \"\"\"\n",
    "        _data holds column names mapped to arrays\n",
    "        Dictionaries are ordered from Python 3.6+\n",
    "        Hence using that to put columns in correct order in list\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of column names\n",
    "        \"\"\"\n",
    "        # if you iterate through a dict, you only get the keys and not the values.\n",
    "        return list(self._data)\n",
    "\n",
    "    @columns.setter\n",
    "    def columns(self, columns):\n",
    "        \"\"\"\n",
    "        Must supply a list of columns as strings the same length as the current DataFrame\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        columns: list of strings\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if not isinstance(columns, list):\n",
    "            raise TypeError('`columns` must be a list')\n",
    "        if len(columns) != len(self._data):\n",
    "            raise ValueError('Newly created `columns` must have the same length as the current DataFrame')\n",
    "        for col in columns:\n",
    "            if not isinstance(col, str):\n",
    "                raise TypeError('All column names must be of type str')\n",
    "        if len(columns) != len(set(columns)):\n",
    "            raise ValueError('`columns` cannot have duplicates')\n",
    "        # updating _data\n",
    "        new_data = dict(zip(columns, self._data.values()))\n",
    "        self._data = new_data\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        Two-item tuple of no. of rows and columns\n",
    "        \"\"\"\n",
    "        return len(self), len(self._data)\n",
    "\n",
    "    # ToDo: Complete this method\n",
    "    def _repr_html_(self):\n",
    "        \"\"\"\n",
    "        Used to create a string of HTML to nicely display the DataFrame in a Jupyter Notebook.\n",
    "        Different string formatting is used for different data types.\n",
    "\n",
    "        The structure of HTML is as follows:\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th>data</th>\n",
    "                    ...\n",
    "                    <th>data</th>\n",
    "                </tr>\n",
    "            <//thead>\n",
    "            <tbody>\n",
    "                <tr>\n",
    "                    <td><strong>{i}</strong></td>\n",
    "                    <td>data</td>\n",
    "                    ...\n",
    "                    <td>data</td>\n",
    "                </tr>\n",
    "                ...\n",
    "                <tr>\n",
    "                    <td><strong>{i}</strong></td>\n",
    "                    <td>data</td>\n",
    "                    ...\n",
    "                    <td>data</td>\n",
    "                </tr>\n",
    "            </tbody>\n",
    "        </table>\n",
    "        \"\"\"\n",
    "        html = '<table><thead><tr><th></th>'\n",
    "        for col in self.columns:\n",
    "            html += f\"<th>{col:10}</th>\"\n",
    "\n",
    "        html += '</tr></thead>'\n",
    "        html += \"<tbody>\"\n",
    "\n",
    "        only_head = False\n",
    "        num_head = 10\n",
    "        num_tail = 10\n",
    "        if len(self) <= 20:\n",
    "            only_head = True\n",
    "            num_head = len(self)\n",
    "\n",
    "        for i in range(num_head):\n",
    "            html += f'<tr><td><strong>{i}</strong></td>'\n",
    "            for col, values in self._data.items():\n",
    "                kind = values.dtype.kind\n",
    "                if kind == 'f':\n",
    "                    html += f'<td>{values[i]:10.3f}</td>'\n",
    "                elif kind == 'b':\n",
    "                    html += f'<td>{values[i]}</td>'\n",
    "                elif kind == 'O':\n",
    "                    v = values[i]\n",
    "                    if v is None:\n",
    "                        v = 'None'\n",
    "                    html += f'<td>{v:10}</td>'\n",
    "                else:\n",
    "                    html += f'<td>{values[i]:10}</td>'\n",
    "            html += '</tr>'\n",
    "\n",
    "        if not only_head:\n",
    "            html += '<tr><strong><td>...</td></strong>'\n",
    "            for i in range(len(self.columns)):\n",
    "                html += '<td>...</td>'\n",
    "            html += '</tr>'\n",
    "            for i in range(-num_tail, 0):\n",
    "                html += f'<tr><td><strong>{len(self) + i}</strong></td>'\n",
    "                for col, values in self._data.items():\n",
    "                    kind = values.dtype.kind\n",
    "                    if kind == 'f':\n",
    "                        html += f'<td>{values[i]:10.3f}</td>'\n",
    "                    elif kind == 'b':\n",
    "                        html += f'<td>{values[i]}</td>'\n",
    "                    elif kind == 'O':\n",
    "                        v = values[i]\n",
    "                        if v is None:\n",
    "                            v = 'None'\n",
    "                        html += f'<td>{v:10}</td>'\n",
    "                    else:\n",
    "                        html += f'<td>{values[i]:10}</td>'\n",
    "                html += '</tr>'\n",
    "\n",
    "        html += '</tbody></table>'\n",
    "        return html\n",
    "\n",
    "    @property\n",
    "    def values(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        A single 2D NumPy array of all the columns of data. \n",
    "        \"\"\"\n",
    "        # https://numpy.org/doc/stable/reference/generated/numpy.column_stack.html\n",
    "        return np.column_stack(list(self._data.values()))\n",
    "\n",
    "    @property\n",
    "    def dtypes(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        A two-column DataFrame of column names in one column and their data type in the other\n",
    "        \"\"\"\n",
    "        DTYPE_NAME = {'O': 'string', 'i': 'int', 'f': 'float', 'b': 'bool'}\n",
    "        col_names = np.array(self.columns)\n",
    "        dtypes = []\n",
    "        for value in self._data.values():\n",
    "            kind = value.dtype.kind\n",
    "            dtype = DTYPE_NAME[kind]\n",
    "            dtypes.append(dtype)\n",
    "        new_data = {'Column Name': col_names, 'Data Type': np.array(dtypes)}\n",
    "\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        Use the brackets operator to simultaneously select rows and columns\n",
    "        A single string selects one column -> df['colname']\n",
    "        A list of strings selects multiple columns -> df[['colname1', 'colname2']]\n",
    "        A one column DataFrame of booleans that filters rows -> df[df_bool]\n",
    "        Row and column selection simultaneously -> df[rs, cs]\n",
    "            where cs and rs can be integers, slices, or a list of integers\n",
    "            rs can also be a one-column boolean DataFrame\n",
    "        Returns\n",
    "        -------\n",
    "        A subset of the original DataFrame\n",
    "        \"\"\"\n",
    "        # select a single column -> df['colname']\n",
    "        if isinstance(item, str):\n",
    "            return DataFrame({item: self._data[item]})\n",
    "\n",
    "        # select multiple columns -> df[['colname1', 'colname2']]\n",
    "        if isinstance(item, list):\n",
    "            return DataFrame({col: self._data[col] for col in item})\n",
    "\n",
    "        # boolean selection\n",
    "        if isinstance(item, DataFrame):\n",
    "            if item.shape[1] != 1:\n",
    "                raise ValueError('Can only pass a one column DataFrame for selection')\n",
    "\n",
    "            # _data.values()[0] cannot be used as\n",
    "            # 'dict_values' doesn't allow indexing\n",
    "            bool_arr = next(iter(item._data.values()))\n",
    "            if bool_arr.dtype.kind != 'b':\n",
    "                raise TypeError('DataFrame must be a boolean')\n",
    "\n",
    "            new_data = {}\n",
    "            for col, values in self._data.items():\n",
    "                # values[bool_arr] -> NumPy does boolean selection. \n",
    "                new_data[col] = values[bool_arr]\n",
    "            return DataFrame(new_data)\n",
    "\n",
    "        if isinstance(item, tuple):\n",
    "            return self._getitem_tuple(item)\n",
    "        else:\n",
    "            raise TypeError('Select with either a string, a list, or a row and column '\n",
    "                            'simultaneous selection')\n",
    "\n",
    "    def _getitem_tuple(self, item):\n",
    "        # simultaneous selection of rows and cols -> df[rs, cs]\n",
    "        if len(item) != 2:\n",
    "            raise ValueError('Pass either a single string or a two-item tuple inside the '\n",
    "                                'selection operator.')\n",
    "        row_selection, col_selection = item\n",
    "        if isinstance(row_selection, int):\n",
    "            row_selection = [row_selection]\n",
    "        # df[df['a'] < 10, 'b'] \n",
    "        elif isinstance(row_selection, DataFrame):\n",
    "            if row_selection.shape[1] != 1:\n",
    "                raise ValueError('Can only pass a one column DataFrame for selection')\n",
    "            row_selection = next(iter(row_selection._data.values()))\n",
    "            if row_selection.dtype.kind != 'b':\n",
    "                raise TypeError('DataFrame must be a boolean')\n",
    "        elif not isinstance(row_selection, (list, slice)):\n",
    "            raise TypeError('Row selection must be either an int, slice, list, or DataFrame')\n",
    "\n",
    "        if isinstance(col_selection, int):\n",
    "            col_selection = [self.columns[col_selection]]\n",
    "        elif isinstance(col_selection, str):\n",
    "            col_selection = [col_selection]\n",
    "        elif isinstance(col_selection, list):\n",
    "            new_col_selection = []\n",
    "            for col in col_selection:\n",
    "                if isinstance(col, int):\n",
    "                    # converting col to string\n",
    "                    new_col_selection.append(self.columns[col])\n",
    "                else:\n",
    "                    # assuming col is a string\n",
    "                    new_col_selection.append(col)\n",
    "            col_selection = new_col_selection\n",
    "        elif isinstance(col_selection, slice):\n",
    "            start = col_selection.start\n",
    "            stop = col_selection.stop\n",
    "            step = col_selection.step\n",
    "            if isinstance(start, str):\n",
    "                start = self.columns.index(start)\n",
    "            if isinstance(stop, str):\n",
    "                # added 1 to include the last column\n",
    "                stop = self.columns.index(stop) + 1\n",
    "            if isinstance(step, int):\n",
    "                raise TypeError('`step` must be of type integer')\n",
    "\n",
    "            col_selection = self.columns[start:stop:step]\n",
    "        else:\n",
    "            raise TypeError('Column selection must be either an int, string, list, or slice')\n",
    "\n",
    "        new_data = {}\n",
    "        for col in col_selection:\n",
    "            new_data[col] = self._data[col][row_selection]\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    def _ipython_key_completions_(self):\n",
    "        # allows for tab completion when doing df['c\n",
    "        return self.columns\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        # add a new column or overwrite an exisiting column\n",
    "        if not isinstance(key, str):\n",
    "            raise NotImplementedError('Can only set a single column')\n",
    "\n",
    "        if isinstance(value, np.ndarray):\n",
    "            if value.ndim != 1:\n",
    "                raise ValueError('The setting array must be one dimensional')\n",
    "            if len(value) != len(self):\n",
    "                raise ValueError('Setting array must be of the same length as the DataFrame')\n",
    "        elif isinstance(value, DataFrame):\n",
    "            if value.shape[1] != 1:\n",
    "                raise ValueError('Setting DataFrame must be one column')\n",
    "            if len(value) != len(self):\n",
    "                raise ValueError('Setting and Calling DataFrames must be the same length')\n",
    "            # reassign value to the underlying numpy array of the column.\n",
    "            value = next(iter(value._data.values()))\n",
    "        elif isinstance(value, (int, str, bool, float)):\n",
    "            value = np.repeat(value, len(self))\n",
    "        else:\n",
    "            raise TypeError('Setting value must either be a NumPy array, DataFrame, integer, string, float, or boolean')\n",
    "\n",
    "        if value.dtype.kind == 'U':\n",
    "            value = value.astype('O')\n",
    "        \n",
    "        self._data[key] = value\n",
    "\n",
    "    def head(self, n=5):\n",
    "        \"\"\"\n",
    "        Return the first n rows\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n: int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "        \"\"\"\n",
    "        return self[:n, :]\n",
    "\n",
    "    def tail(self, n=5):\n",
    "        \"\"\"\n",
    "        Return the last n rows\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n: int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "        \"\"\"\n",
    "        return self[-n:, :]\n",
    "\n",
    "    ### Aggregation Methods ###\n",
    "\n",
    "    def min(self):\n",
    "        return self._agg(np.min)\n",
    "\n",
    "    def max(self):\n",
    "        return self._agg(np.max)\n",
    "\n",
    "    def mean(self):\n",
    "        return self._agg(np.mean)\n",
    "\n",
    "    def median(self):\n",
    "        return self._agg(np.median)\n",
    "\n",
    "    def sum(self):\n",
    "        return self._agg(np.sum)\n",
    "\n",
    "    def var(self):\n",
    "        return self._agg(np.var)\n",
    "\n",
    "    def std(self):\n",
    "        return self._agg(np.std)\n",
    "\n",
    "    def all(self):\n",
    "        return self._agg(np.all)\n",
    "\n",
    "    def any(self):\n",
    "        return self._agg(np.any)\n",
    "\n",
    "    def argmax(self):\n",
    "        return self._agg(np.argmax)\n",
    "\n",
    "    def argmin(self):\n",
    "        return self._agg(np.argmin)\n",
    "\n",
    "    def _agg(self, aggfunc):\n",
    "        \"\"\"\n",
    "        Generic aggregation function that applies the aggregation to each column\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        aggfunc: str of the aggregation function name in NumPy\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "        \"\"\"\n",
    "        new_data = {}\n",
    "        for col, value in self._data.items():\n",
    "            try: \n",
    "                new_data[col] = np.array([aggfunc(value)])\n",
    "            except TypeError:\n",
    "                pass\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    def isna(self):\n",
    "        \"\"\"\n",
    "        Determines whether each value in the DataFrame is missing or not\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame of booleans the same size as the calling DataFrame\n",
    "        \"\"\"\n",
    "        new_data = {}\n",
    "        for col, value in self._data.items():\n",
    "            kind = value.dtype.kind\n",
    "            if kind == 'O':\n",
    "                new_data[col] = value == None\n",
    "            else:\n",
    "                new_data[col] = np.isnan(value)\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    def count(self):\n",
    "        \"\"\"\n",
    "        Counts the number of non-missing values per column\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "        \"\"\"\n",
    "        new_data = {}\n",
    "        df = self.isna()\n",
    "        length = len(df)        \n",
    "        for col, value in df._data.items():\n",
    "            val = length - value.sum()\n",
    "            new_data[col] = np.array([val])\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    # In Pandas, only series have unique method, not DataFrames\n",
    "    def unique(self):\n",
    "        \"\"\"\n",
    "        Find the unique values of each column\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A list of one-column DataFrames\n",
    "        \"\"\"\n",
    "        # @ToDo: Cover the case for missing values in strings\n",
    "        dfs = []\n",
    "        for col, value in self._data.items():\n",
    "            new_data = {col: np.unique(value)}\n",
    "            dfs.append(DataFrame(new_data))\n",
    "        if len(dfs) == 1:\n",
    "            return dfs[0]\n",
    "        return dfs\n",
    "\n",
    "    def nunique(self):\n",
    "        \"\"\"\n",
    "        Find the number of unique values in each column\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        new_data = {}\n",
    "        for col, value in self._data.items():\n",
    "            new_data[col] = np.array([len(np.unique(value))])\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    def value_counts(self, normalize=False):\n",
    "        \"\"\"\n",
    "        Returns the frequency of each unique value for each column\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        normalize: bool\n",
    "        If True, returns the relative frequencies(percent)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A list of DataFrames or a single DataFrame if one column\n",
    "        \"\"\"\n",
    "        dfs = []\n",
    "        for col, value in self._data.items():\n",
    "            uniques, raw_counts = np.unique(value, return_counts=True)\n",
    "\n",
    "            # Sort counts from greatest to lowest\n",
    "            order = np.argsort(-raw_counts)\n",
    "            uniques = uniques[order]\n",
    "            raw_counts = raw_counts[order]\n",
    "\n",
    "            if normalize:\n",
    "                raw_counts = raw_counts / raw_counts.sum()\n",
    "            df = DataFrame({col: uniques, 'count': raw_counts })\n",
    "            dfs.append(df)\n",
    "        if len(dfs) == 1:\n",
    "            return dfs[0]\n",
    "        return dfs\n",
    "\n",
    "    def rename(self, columns):\n",
    "        \"\"\"\n",
    "        Renames columns in the DataFrame\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        columns: dict \n",
    "            A dictionary mapping the old column name to the new column name\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        if not isinstance(columns, dict):\n",
    "            raise TypeError('`columns` must be a dictionary')\n",
    "        new_data = {}\n",
    "        for col, value in self._data.items():\n",
    "            new_col = columns.get(col, col)\n",
    "            new_data[new_col] = value\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    def drop(self, columns):\n",
    "        \"\"\"\n",
    "        Drops one or more columns from a DataFrame\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        columns: str or list of strings\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        if isinstance(columns, str):\n",
    "            columns = [columns]\n",
    "        elif not isinstance(columns, list):\n",
    "            raise TypeError('`columns` must be either a string or list')\n",
    "        new_data = {}\n",
    "        for col, value in self._data.items():\n",
    "            if not col in columns:\n",
    "                new_data[col] = value\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    ### Non-Aggregation Methods ###\n",
    "\n",
    "    def abs(self):\n",
    "        \"\"\"\n",
    "        Takes the absolute value of each value in the DataFrame\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        return self._non_agg(np.abs)\n",
    "\n",
    "    def cummin(self):\n",
    "        \"\"\"\n",
    "        Finds cumulative minimum by column\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        return self._non_agg(np.minimum.accumulate)\n",
    "\n",
    "    def cummax(self):\n",
    "        \"\"\"\n",
    "        Finds cumulative maximum by column\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        return self._non_agg(np.maximum.accumulate)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"\n",
    "        Finds cumulative sum by column\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        return self._non_agg(np.cumsum)\n",
    "\n",
    "    def clip(self, lower=None, upper=None):\n",
    "        \"\"\"\n",
    "        All values less than lower will be set to lower\n",
    "        All values greater than upper will be set to upper\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lower: number or None\n",
    "        upper: number or None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        return self._non_agg(np.clip, a_min=lower, a_max=upper)\n",
    "\n",
    "    def round(self, n):\n",
    "        \"\"\"\n",
    "        Rounds values to the nearest n decimals\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        return self._non_agg(np.round, 'if', decimals=n)\n",
    "\n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        Copies the DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        return self._non_agg(np.copy)\n",
    "\n",
    "    # To Do: Write a better solution\n",
    "    def _non_agg(self, funcname, kinds='bif', **kwargs):\n",
    "        \"\"\"\n",
    "        Generic non-aggregation function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        funcname: numpy function\n",
    "        args: extra arguments for certain functions\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        new_data = {}\n",
    "        for col, values in self._data.items():\n",
    "            if values.dtype.kind in kinds:\n",
    "                values = funcname(values, **kwargs)\n",
    "            else:\n",
    "                values = values.copy()\n",
    "            new_data[col] = values\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    def diff(self, n=1):\n",
    "        \"\"\"\n",
    "        Take the difference between the current value and the nth value above it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n: int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        def func(value):\n",
    "            value = value.astype('float')\n",
    "            value_shifted = np.roll(value, n)\n",
    "            value = value - value_shifted\n",
    "            if n >= 0:\n",
    "                value[:n] = np.nan\n",
    "            else:\n",
    "                value[n:] = np.nan\n",
    "            return value\n",
    "        return self._non_agg(func)\n",
    "\n",
    "    def pct_change(self, n=1):\n",
    "        \"\"\"\n",
    "        Take the percentage difference between the current value and the nth value above it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n: int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        def func(value):\n",
    "            value = value.astype('float')\n",
    "            value_shifted = np.roll(value, n)\n",
    "            value = value - value_shifted\n",
    "            if n >= 0:\n",
    "                value[:n] = np.nan\n",
    "            else:\n",
    "                value[n:] = np.nan\n",
    "            return value / value_shifted\n",
    "        return self._non_agg(func)\n",
    "\n",
    "    ### Arithmetic and Comparison Operators ###\n",
    "\n",
    "    # https://docs.python.org/3/reference/datamodel.html#emulating-numeric-type\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return self._oper('__add__', other)\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self._oper('__radd__', other)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return self._oper('__sub__', other)\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return self._oper('__rsub__', other)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return self._oper('__mul__', other)\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self._oper('__rmul__', other)\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        return self._oper('__truediv__', other)\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        return self._oper('__rtruediv__', other)\n",
    "\n",
    "    def __floordiv__(self, other):\n",
    "        return self._oper('__floordiv__', other)\n",
    "\n",
    "    def __rfloordiv__(self, other):\n",
    "        return self._oper('__rfloordiv__', other)\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        return self._oper('__pow__', other)\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        return self._oper('__rpow__', other)\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self._oper('__gt__', other)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self._oper('__lt__', other)\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        return self._oper('__ge__', other)\n",
    "\n",
    "    def __le__(self, other):\n",
    "        return self._oper('__le__', other)\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return self._oper('__ne__', other)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self._oper('__eq__', other)\n",
    "\n",
    "    def _oper(self, op, other):\n",
    "        \"\"\"\n",
    "        Generic operator method\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        op: str Name of special method\n",
    "        other: the other object being operated on\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        if isinstance(other, DataFrame):\n",
    "            if other.shape[1] != 1:\n",
    "                raise ValueError('`other` must be a one-column DataFrame')\n",
    "            other = next(iter(other._data.values()))\n",
    "        new_data = {}\n",
    "        for col, value in self._data.items():\n",
    "            func = getattr(value, op)\n",
    "            new_data[col] = func(other)\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    def sort_values(self, by, asc=True):\n",
    "        \"\"\"\n",
    "        Sort the DataFrame by one or more values\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        by: str or list of column names\n",
    "        asc: boolean of sorting order\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "        \"\"\"\n",
    "        if isinstance(by, str):\n",
    "            order = np.argsort(self._data[by])\n",
    "        elif isinstance(by, list):\n",
    "            cols = [self._data[col] for col in by[::-1]]\n",
    "            order = np.lexsort(cols)\n",
    "        else:\n",
    "            raise TypeError('`by` must be a str or a list')\n",
    "        if not asc:\n",
    "            order = order[::-1]\n",
    "        return self[order.tolist(), :]\n",
    "        \n",
    "    def sample(self, n=None, frac=None, replace=False, seed=None):\n",
    "        \"\"\"\n",
    "        Randomly samples rows of the DataFrame\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n: int\n",
    "            number of rows to return\n",
    "        frac: float\n",
    "            Proportion of the data to sample\n",
    "        replace: bool\n",
    "            Whether or not to sample with replacement\n",
    "        seed: int\n",
    "            Seed the random number generator\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        if seed:\n",
    "            np.random.seed(seed)\n",
    "        if frac is not None:\n",
    "            if frac <= 0:\n",
    "                raise ValueError('`frac` must be positive')\n",
    "            n = int(frac * len(self))\n",
    "        if n is not None:\n",
    "            if not isinstance(n, int):\n",
    "                raise TypeError('`n` must be of type int')\n",
    "            rows = np.random.choice(range(len(self)), size=n, replace=replace)\n",
    "        return self[rows.tolist(), :]\n",
    "    \n",
    "    def pivot_table(self, rows=None, columns=None, values=None, aggfunc=None):\n",
    "        \"\"\"\n",
    "        Creates a pivot table from one or two 'grouping' columns\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rows: str of column name to group by\n",
    "            Optional\n",
    "        columns: str of column name to group by\n",
    "            Optional\n",
    "        values: str of column name to aggregate\n",
    "            Required\n",
    "        aggfunc: str of aggregation function\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        if rows is None and columns is None:\n",
    "            raise ValueError('`rows` or `columns` both cannot be `None`')\n",
    "\n",
    "        if values is not None:\n",
    "            val_data = self._data[values]\n",
    "            if aggfunc is None:\n",
    "                raise ValueError('You must provide `aggfunc` if `values` is provided')\n",
    "        else:\n",
    "            if aggfunc is None:\n",
    "                aggfunc = 'size'\n",
    "                val_data = np.empty(len(self))\n",
    "            else:\n",
    "                raise ValueError('You cannot provide `aggfunc` when `values` is `None`')\n",
    "\n",
    "        if rows is not None:\n",
    "            row_data = self._data[rows]\n",
    "        \n",
    "        if columns is not None:\n",
    "            col_data = self._data[columns]\n",
    "\n",
    "        if rows is None:\n",
    "            pivot_type = 'columns'\n",
    "        elif columns is None:\n",
    "            pivot_type = 'rows'\n",
    "        else:\n",
    "            pivot_type = 'all'\n",
    "\n",
    "        from collections import defaultdict\n",
    "        d = defaultdict(list)\n",
    "        if pivot_type == 'columns':\n",
    "            for group, val in zip(col_data, val_data):\n",
    "                d[group].append(val)\n",
    "        elif pivot_type == 'rows':\n",
    "            for group, val in zip(row_data, val_data):\n",
    "                d[group].append(val)\n",
    "        else:\n",
    "            for group1, group2, val in zip(row_data, col_data, val_data):\n",
    "                d[(group1, group2)].append(val)\n",
    "\n",
    "        # aggregation function\n",
    "        agg_dict = {}\n",
    "        for group, val in d.items():\n",
    "            arr = np.array(val)\n",
    "            func = getattr(np, aggfunc)\n",
    "            agg_dict[group] = func(arr)\n",
    "\n",
    "        # dataframe representation\n",
    "        new_data = {}\n",
    "        if pivot_type == 'columns':\n",
    "            for col in sorted(agg_dict):\n",
    "                value = agg_dict[col]\n",
    "                new_data[col] = np.array([value])\n",
    "        elif pivot_type == 'rows':\n",
    "            row_vals = np.array(list(agg_dict.keys()))\n",
    "            vals = np.array(list(agg_dict.values()))\n",
    "\n",
    "            order = np.argsort(row_vals)\n",
    "            new_data[rows] = row_vals[order]\n",
    "            new_data[aggfunc] = vals[order]\n",
    "        else:\n",
    "            row_set = set()\n",
    "            col_set = set()\n",
    "            # group is a two-item tuple \n",
    "            for group in agg_dict:\n",
    "                row_set.add(group[0])\n",
    "                col_set.add(group[1])\n",
    "            row_list = sorted(row_set)\n",
    "            col_list = sorted(col_set)\n",
    "            new_data[rows] = np.array(row_list)\n",
    "\n",
    "            for col in col_list:\n",
    "                new_vals = []\n",
    "                for row in row_list:\n",
    "                    new_val = agg_dict.get((row, col), np.nan)\n",
    "                    new_vals.append(new_val)\n",
    "                new_data[col] = np.array(new_vals)\n",
    "        return DataFrame(new_data)\n",
    "\n",
    "    def _add_docs(self):\n",
    "        agg_names = ['min', 'max', 'mean', 'median', 'sum', 'var', 'std', 'any', 'all', 'argmax', 'argmin']\n",
    "        agg_doc = \\\n",
    "        \"\"\"\n",
    "        Find the {} of each column\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        for name in agg_names:\n",
    "            getattr(DataFrame, name).__doc__ = agg_doc.format(name)\n",
    "\n",
    "class StringMethods:\n",
    "    # TODO : Add Docs for each method\n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "\n",
    "    def capitalize(self, col):\n",
    "        return self._str_method(str.capitalize, col)\n",
    "\n",
    "    def center(self, col, width, fillchar=None):\n",
    "        if fillchar is None:\n",
    "            fillchar = ' '\n",
    "        return self._str_method(str.center, col, width, fillchar)\n",
    "\n",
    "    def count(self, col, sub, start=None, stop=None):\n",
    "        return self._str_method(str.count, col, sub, start, stop)\n",
    "\n",
    "    def endswith(self, col, suffix, start=None, stop=None):\n",
    "        return self._str_method(str.endswith, col, suffix, start, stop)\n",
    "\n",
    "    def startswith(self, col, suffix, start=None, stop=None):\n",
    "        return self._str_method(str.startswith, col, suffix, start, stop)\n",
    "\n",
    "    def find(self, col, sub, start=None, stop=None):\n",
    "        return self._str_method(str.find, col, sub, start, stop)\n",
    "\n",
    "    def len(self, col):\n",
    "        return self._str_method(str.__len__, col)\n",
    "\n",
    "    def get(self, col, item):\n",
    "        return self._str_method(str.__getitem__, col, item)\n",
    "\n",
    "    def index(self, col, sub, start=None, stop=None):\n",
    "        return self._str_method(str.index, col, sub, start, stop)\n",
    "\n",
    "    def isalnum(self, col):\n",
    "        return self._str_method(str.isalnum, col)\n",
    "\n",
    "    def isalpha(self, col):\n",
    "        return self._str_method(str.isalpha, col)\n",
    "\n",
    "    def isdecimal(self, col):\n",
    "        return self._str_method(str.isdecimal, col)\n",
    "\n",
    "    def islower(self, col):\n",
    "        return self._str_method(str.islower, col)\n",
    "\n",
    "    def isnumeric(self, col):\n",
    "        return self._str_method(str.isnumeric, col)\n",
    "\n",
    "    def isspace(self, col):\n",
    "        return self._str_method(str.isspace, col)\n",
    "\n",
    "    def istitle(self, col):\n",
    "        return self._str_method(str.istitle, col)\n",
    "\n",
    "    def isupper(self, col):\n",
    "        return self._str_method(str.isupper, col)\n",
    "\n",
    "    def lstrip(self, col, chars):\n",
    "        return self._str_method(str.lstrip, col, chars)\n",
    "\n",
    "    def rstrip(self, col, chars):\n",
    "        return self._str_method(str.rstrip, col, chars)\n",
    "\n",
    "    def strip(self, col, chars):\n",
    "        return self._str_method(str.strip, col, chars)\n",
    "\n",
    "    def replace(self, col, old, new, count=None):\n",
    "        if count is None:\n",
    "            count = -1\n",
    "        return self._str_method(str.replace, col, old, new, count)\n",
    "\n",
    "    def swapcase(self, col):\n",
    "        return self._str_method(str.swapcase, col)\n",
    "\n",
    "    def title(self, col):\n",
    "        return self._str_method(str.title, col)\n",
    "\n",
    "    def lower(self, col):\n",
    "        return self._str_method(str.lower, col)\n",
    "\n",
    "    def upper(self, col):\n",
    "        return self._str_method(str.upper, col)\n",
    "\n",
    "    def zfill(self, col, width):\n",
    "        return self._str_method(str.zfill, col, width)\n",
    "\n",
    "    def encode(self, col, encoding='utf-8', errors='strict'):\n",
    "        return self._str_method(str.encode, col, encoding, errors)\n",
    "\n",
    "    def _str_method(self, method, col, *args):\n",
    "        \"\"\"\n",
    "        Generic string method\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        method: existing string methods in Python\n",
    "        col: str name of the column\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A DataFrame\n",
    "        \"\"\"\n",
    "        old_values = self._df._data[col]\n",
    "        if old_values.dtype.kind != 'O':\n",
    "            raise TypeError('The `str` accessor only works with string columns')\n",
    "        new_values = []\n",
    "        for val in old_values:\n",
    "            if val is None:\n",
    "                new_values.append(None)\n",
    "            else:\n",
    "                new_val = method(val, *args)\n",
    "                new_values.append(new_val)\n",
    "        return DataFrame({col: np.array(new_values)})\n",
    "\n",
    "# TODO: Handle case of boolean data\n",
    "\n",
    "def read_csv(file,header=0):\n",
    "    \"\"\"\n",
    "    Read a simple comma-separated-value(CSV) file as a DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file: str of file location\n",
    "    header: index value of header \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A DataFrame\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    data = defaultdict(list)\n",
    "    with open(file) as f:\n",
    "        reader = csv.reader(f, delimiter=',', skipinitialspace=True)\n",
    "        if header == None:\n",
    "            with open(file) as nc:\n",
    "                readers = csv.reader(nc, delimiter=',', skipinitialspace=True)\n",
    "                first_row = next(readers)\n",
    "                num_cols = len(first_row)\n",
    "                column_names = [str(n) for n in range(0,num_cols)]  \n",
    "            for line in f:\n",
    "                values = line.strip('\\n').split(',')\n",
    "                for col, val in zip(column_names, values):\n",
    "                    data[col].append(val)    \n",
    "        elif header != 0:\n",
    "            for header in range(0,header):\n",
    "                skip_header_number = next(reader)\n",
    "                num_cols = len(skip_header_number)\n",
    "                column_names = [str(n) for n in range(0,num_cols)]  \n",
    "            for line in f:\n",
    "                values = line.strip('\\n').split(',')\n",
    "                for col, val in zip(column_names, values):\n",
    "                    data[col].append(val)    \n",
    "        else:   \n",
    "            header = f.readline()\n",
    "            column_names = header.strip('\\n').split(',')    \n",
    "            for line in f:\n",
    "                values = line.strip('\\n').split(',')\n",
    "                for col, val in zip(column_names, values):\n",
    "                    data[col].append(val)\n",
    "    # return data\n",
    "    new_data = {}\n",
    "    # vals is a list of strings\n",
    "    for col, vals in data.items():\n",
    "        try:\n",
    "            new_data[col] = np.array(vals, dtype='int')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                new_data[col] = np.array(vals, dtype='float')\n",
    "            except ValueError:\n",
    "                new_data[col] = np.array(vals, dtype='O')\n",
    "    return DataFrame(new_data)\n",
    "\n",
    "data = read_csv(r'C:\\Users\\priya\\OneDrive\\Documents\\ickle\\dataset\\employee.csv');\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdab48f7-5f5d-43d3-9f66-d1d4647757e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3102c81-338d-4132-89a0-b3dd2211566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>played_at</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [song_name, artist_name, played_at, ts]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATABASE_ENGINE = \"postgresql+psycopg2://postgres:pri123@localhost:5432/spotify_trends\"\n",
    "\n",
    "conn = sqlalchemy.create_engine(DATABASE_ENGINE)\n",
    "\n",
    "#read_sql_table(table_name, con[, schema, ...])\n",
    "data = pd.read_sql_table(\"my_played_tracks\", schema=\"tracks\", con=conn)\n",
    "data.head()\n",
    "\n",
    "data = pd.read_sql_query(\"select * from tracks.my_played_tracks\", con=conn)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "950a0736-fbab-4692-83c0-e545898608b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "b'NTM1ZmIyNmI1MzZkNGVkNDkwMGExNDZlZmIyMzVkY2Q6MmJhODg5MWZkNTllNDFjY2FmZTYzZjlhYzY1YjRkZTc='\n",
      "{'access_token': 'BQCRFgzTC151J9o86yCYDmIr7CIbMYbVKy8mmG8XkkYfT-BhJ57ASJxQbdxu3X2EJqfzs8nfhUNOC0ic2ETwCQc8vUeiolouOkKKhtn2P41o4UyOstw', 'token_type': 'Bearer', 'expires_in': 3600}\n"
     ]
    }
   ],
   "source": [
    "import requests as re\n",
    "from base64 import urlsafe_b64encode\n",
    "import six\n",
    "\n",
    "TOKEN_URL = 'https://accounts.spotify.com/api/token'\n",
    "BASE_URL = 'https://api.spotify.com/v1/'\n",
    "\n",
    "#get auth code\n",
    "auth_code = re.get(\"https://accounts.spotify.com/authorize\", \n",
    "                   {\"CLIENT_ID\":\"535fb26b536d4ed4900a146efb235dcd\",\n",
    "                    'response_type': 'code',\n",
    "                    'redirect_uri':'https://open.spotify.com',\n",
    "                   })\n",
    "print(auth_code)\n",
    "\n",
    "#set header \n",
    "CLIENT_ID = \"535fb26b536d4ed4900a146efb235dcd\"\n",
    "CLIENT_SECRET = \"2ba8891fd59e41ccafe63f9ac65b4de7\"\n",
    "auth_header = base64.b64encode(\n",
    "        six.text_type(CLIENT_ID + \":\" + CLIENT_SECRET).encode(\"ascii\")\n",
    "    )\n",
    "print(auth_header)\n",
    "\n",
    "headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Authorization': 'Basic %s' % auth_header.decode(\"ascii\")\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    'grant_type':\"client_credentials\",\n",
    "    'code': auth_code,\n",
    "    'redirect_uri':'https://open.spotify.com'\n",
    "    }\n",
    "\n",
    "# Make a request to the /token endpoint to get an access token\n",
    "access_token_request = re.post(url=TOKEN_URL, data=payload, headers=headers)\n",
    "\n",
    "# convert the response to JSON\n",
    "access_token_response_data = access_token_request.json()\n",
    "\n",
    "print(access_token_response_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420d3649-1bf8-4983-8d67-f4a8ab50ee3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th></th><th>dept      </th></tr></thead><tbody><tr><td><strong>0</strong></td><td>Houston Police Department-HPD</td></tr><tr><td><strong>1</strong></td><td>Houston Fire Department (HFD)</td></tr><tr><td><strong>2</strong></td><td>Houston Police Department-HPD</td></tr><tr><td><strong>3</strong></td><td>Public Works & Engineering-PWE</td></tr><tr><td><strong>4</strong></td><td>Houston Airport System (HAS)</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<ickle.DataFrame at 0x21bb5f1a530>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ickle as i\n",
    "data = i.read_csv(r'C:\\Users\\priya\\OneDrive\\Documents\\ickle\\dataset\\employee.csv');\n",
    "data = data.str.center('dept', 11, 'a')\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
